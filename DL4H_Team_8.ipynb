{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T9Kgz-IaXh1o"
   },
   "source": [
    "\n",
    "# Reproduction of Deep learning improves prediction of drug–drug and drug–food interactions<sup>[1]</sup>\n",
    "---\n",
    "Team: **Ahmad Sadeed** (asadeed2), **Andrew Vamos** (avamos2), **Jonathon Green** (jg70)\n",
    "\n",
    "Date: May 7, 2024\n",
    "\n",
    "Overview: This Google Colab Jupyter notebook contains a demonstration of how the model for the original paper by Ryu et al<sup>[1]</sup> can be trained successfully using the ChemicalX DDI Python package<sup>[2]</sup>. Here, we demonstrate successful training of a small sized model within Colab, then load in fully trained models (via gdown) which were trained locally and plot their performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p4M659BKCX_3"
   },
   "source": [
    "## Install Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bKdOpIxh7URZ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from IPython.display import display, Javascript\n",
    "\n",
    "prebuilt = False\n",
    "arch_x86_64 = True\n",
    "\n",
    "if prebuilt and arch_x86_64:\n",
    "\n",
    "  def show_alert(message):\n",
    "      js_code = f\"alert('{message}');\"\n",
    "      display(Javascript(js_code))\n",
    "\n",
    "  # Packages needed for the prebuilt wheels\n",
    "  !pip install wheel\n",
    "\n",
    "  # PyTDC-0.4.1-py3-none-any.whl # This package prompts the user to restart the session after it's installed\n",
    "  show_alert(\"Please do not restart this session when prompted.\")\n",
    "  !wget -O PyTDC-0.4.1-py3-none-any.whl https://drive.usercontent.google.com/download?id=1JbHuCkbLIp9BTbNlj3MB75WfTbz_HUkN&export=download&authuser=0\n",
    "  !pip install PyTDC-0.4.1-py3-none-any.whl\n",
    "\n",
    "  # torch_cluster-1.6.3-cp310-cp310-linux_x86_64.whl\n",
    "  !wget -O torch_cluster-1.6.3-cp310-cp310-linux_x86_64.whl https://drive.usercontent.google.com/download?id=18p4c1tfkp_-xX7OMbDrhFDYK3viefOsY&export=download&authuser=0\n",
    "  !pip install torch_cluster-1.6.3-cp310-cp310-linux_x86_64.whl\n",
    "\n",
    "  # torch_scatter-2.1.2-cp310-cp310-linux_x86_64.whl\n",
    "  !wget -O torch_scatter-2.1.2-cp310-cp310-linux_x86_64.whl https://drive.usercontent.google.com/download?id=1wi-QdBqogm2K0UG-V-oZLImJw9kSWQaL&export=download&authuser=0\n",
    "  !pip install torch_scatter-2.1.2-cp310-cp310-linux_x86_64.whl\n",
    "\n",
    "  # chemicalx-0.1.0-py3-none-any.whl\n",
    "  !wget -O chemicalx-0.1.0-py3-none-any.whl https://drive.usercontent.google.com/download?id=1ZuzW7nq1QPHkXZH9keyvWmxm1eHpYqyq&export=download&authuser=0\n",
    "  !pip install chemicalx-0.1.0-py3-none-any.whl\n",
    "\n",
    "else:\n",
    "  !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "  !pip install torch-scatter -f https://data.pyg.org/whl/torch-2.2.2+cu121.html\n",
    "  !pip install torch-cluster -f https://data.pyg.org/whl/torch-2.2.2+cu121.html\n",
    "\n",
    "  # The official package requires 3.8, we're using a fork that's 3.10 compatiable\n",
    "  !pip install git+https://github.com/lucag2/chemicalx#egg=chemicalx # ref [3]\n",
    "\n",
    "# other packages\n",
    "!pip install torchinfo plotly torchsummary ipykernel gdown\n",
    "!pip install --upgrade nbformat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MQ0sNuMePBXx"
   },
   "source": [
    "# Introduction\n",
    "\n",
    "Drug-drug interactions (DDIs) and drug-food interactions (DFIs) significantly impact patient safety and treatment efficacy, presenting complex challenges in pharmacology. Predicting these interactions is crucial but difficult due to the extensive data requirements and often poorly understood mechanisms involved.\n",
    "\n",
    "The paper by Jae Yong Ryu, Hyun Uk Kim, and Sang Yup Lee<sup>[1]</sup> introduces DeepDDI, a computational framework that uses deep learning to predict DDIs and DFIs from basic drug names and structural information. This method significantly advances the state of the art by not only predicting the occurrence of drug interactions but also describing their potential pharmacological effects in human-readable terms, achieving a mean accuracy of 92.4% across 86 DDI types with the DrugBank<sup>[4]</sup> dataset.\n",
    "\n",
    "DeepDDI's innovative approach enhances understanding of drug interactions, supports informed clinical decisions, and offers potential mitigation strategies for adverse effects, marking a substantial contribution to the field.Development of models such as DeepDDI should lead to improved safety around drug administration, particularly as new drugs are introduced to the medical community.\n",
    "\n",
    "Our project aims to replicate the findings of Ryu et al<sup>[1]</sup>. to assess the reproducibility of DeepDDI in a standard computational environment like Google Colab, highlighting its practical implications for improving drug safety and therapeutic strategies.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uygL9tTPSVHB"
   },
   "source": [
    "# Scope of Reproducibility:\n",
    "\n",
    "Our project seeks to validate critical aspects of the DeepDDI model proposed by Ryu et al<sup>[1]</sup>. to assess its practicality, accuracy, and usability in predicting drug-drug and drug-food interactions using a standard computational environment. The following hypotheses from the original paper will be tested with corresponding experiments:\n",
    "\n",
    "**Hypothesis**: DeepDDI can predict drug-drug interactions with high accuracy using only drug names and structural information as inputs.\n",
    "\n",
    "* Experiment: We will replicate the model using the same dataset from DrugBank<sup>[4]</sup> used in the original study. Our experiment will involve retraining the DeepDDI model within our environment (Google Colab) and comparing the prediction accuracy with the reported mean accuracy of 92.4%. This test will confirm if DeepDDI maintains its efficacy across different computational setups.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xWAHJ_1CdtaA"
   },
   "source": [
    "# Methodology\n",
    "\n",
    "This section is organized into two primary subsections: Data and Model, which together describe the comprehensive framework of our experimental setup.\n",
    "\n",
    "\n",
    "* Data: This subsection details the source, structure, and processing of the data used in our experiments, ensuring transparency and reproducibility in how data is handled and prepared for modeling.\n",
    "* Model: This subsection describes the architecture, training, and evaluation of the model. It includes the specific configurations tested, the training process, and the techniques used for model validation.\n",
    "\n",
    "Each part is accompanied by annotated code snippets that not only execute the described procedures but also clarify the purpose and functionality of each step in the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1713154134023,
     "user": {
      "displayName": "Andrew Vamos",
      "userId": "04562579817850856492"
     },
     "user_tz": 240
    },
    "id": "N0jQ00MtR0FX"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "import torch\n",
    "from chemicalx.models import DeepDDI\n",
    "from deepddi import DeepDDI_2\n",
    "from chemicalx.data import BatchGenerator, DrugbankDDI\n",
    "import collections.abc\n",
    "import collections.abc\n",
    "import json\n",
    "from dataclasses import dataclass\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, recall_score, precision_score, f1_score\n",
    "from class_resolver import FunctionResolver\n",
    "from pathlib import Path\n",
    "from typing import List, Mapping, Optional, Sequence, Union\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "from tqdm import trange\n",
    "from chemicalx.models import Model\n",
    "from chemicalx.version import __version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1713154134024,
     "user": {
      "displayName": "Andrew Vamos",
      "userId": "04562579817850856492"
     },
     "user_tz": 240
    },
    "id": "yu61Jp1xrnKk"
   },
   "outputs": [],
   "source": [
    "metric_resolver = FunctionResolver([])\n",
    "metric_resolver.register(roc_auc_score, synonyms={\"roc_auc\", \"auc_roc\", \"auroc\"})\n",
    "metric_resolver.register(accuracy_score, synonyms={\"acc\", \"accuracy\"})\n",
    "metric_resolver.register(recall_score, synonyms={\"recall\"})\n",
    "metric_resolver.register(precision_score, synonyms={\"precision\"})\n",
    "metric_resolver.register(f1_score, synonyms={\"f_score\", \"f1\"})\n",
    "\n",
    "@dataclass\n",
    "class Result:\n",
    "    \"\"\"A result package.\"\"\"\n",
    "\n",
    "    model: Model\n",
    "    predictions: pd.DataFrame\n",
    "    losses: List[float]\n",
    "    losses_val: List[float]\n",
    "    train_time: float\n",
    "    evaluation_time: float\n",
    "    metrics: Mapping[str, float]\n",
    "\n",
    "    def summarize(self) -> None:\n",
    "        \"\"\"Print results to the console.\"\"\"\n",
    "        print(tabulate(sorted(self.metrics.items()), headers=[\"Metric\", \"Value\"]))\n",
    "\n",
    "    def save(self, directory: Union[str, Path]) -> None:\n",
    "        \"\"\"Save the results to a directory.\"\"\"\n",
    "        if isinstance(directory, str):\n",
    "            directory = Path(directory)\n",
    "        directory = directory.resolve()\n",
    "        directory.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "        torch.save(self.model, directory.joinpath(\"model.pkl\"))\n",
    "        directory.joinpath(\"results.json\").write_text(\n",
    "            json.dumps(\n",
    "                {\n",
    "                    \"evaluation\": self.metrics,\n",
    "                    \"losses\": self.losses,\n",
    "                    \"losses_val\": self.losses_val,\n",
    "                    \"training_time\": self.train_time,\n",
    "                    \"evaluation_time\": self.evaluation_time,\n",
    "                    \"chemicalx_version\": __version__,\n",
    "                },\n",
    "                indent=2,\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2NbPHUTMbkD3"
   },
   "source": [
    "##  Data\n",
    "Our project utilizes a comprehensive dataset derived from DrugBank<sup>[4]</sup>, specifically focusing on drug-drug interactions (DDIs). DrugBank<sup>[4]</sup> is a rich bioinformatics and cheminformatics resource that contains detailed drug data including chemical, pharmacological, and pharmaceutical drug information.\n",
    "\n",
    "### Source of the Data:\n",
    "The data for this study is collected from the DrugBank<sup>[4]</sup> database, which provides an extensive array of drug interaction data along with descriptive drug properties. This database is widely used in pharmacological research for both academic and industrial purposes. The data used in this project can be accessed through the DrugBank API directly through ChemicalX<sup>[2]</sup> or by downloading the data directly from [DrugBank's website](https://www.drugbank.ca/)<sup>[4]</sup>.\n",
    "\n",
    "### Statistics:\n",
    "The dataset comprises features for structural similarity profiles of 1706 drugs. A single SSP is a pairwise similarity score between a given drug and 2,159 other DrugBank drug. In total, the dataset includes:\n",
    "\n",
    "* 1706 drugs total\n",
    "* 86 possible drug-drug interaction types (termed contexts)\n",
    "* SSP feature vectors for each drug of length 2159. This can be reduced down for smaller model sized. The original paper used only 50 SSP features for each drug in a given pair, for a 100 length feature total. PCA was used to chose the 50 features\n",
    "* Labeled triples of drug interactions, i.e. triples consiting of [DrugA, DrugB, Context, Label] indicating for a given pair of drugs whether or not a certain interaction is present.\n",
    "* In total, 192,284 DDIs exist for 191,878 drug pairs across the 86 context types.\n",
    "* For training our model, the dataset was divided into a training set (80% of the data), a validation set (10%), and a test set (10%). This split ensures robust testing and validation of the model across unseen data.\n",
    "\n",
    "### Data Process:\n",
    "The data was manipulated as follows:\n",
    "\n",
    "* The dataset was first loaded using a specialized loader that organizes context features, drug features, and labeled triples indicating interactions.\n",
    "* The full dataset was then split into training, validation, and test sets to evaluate the model's performance and prevent overfitting.\n",
    "* Each set is used to create batches of data, which are fed into the model during the training and evaluation phases. These batches include only the drug features to predict interactions, without considering context features or molecular structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 26343,
     "status": "ok",
     "timestamp": 1713154160363,
     "user": {
      "displayName": "Andrew Vamos",
      "userId": "04562579817850856492"
     },
     "user_tz": 240
    },
    "id": "BZScZNbROw-N",
    "outputId": "0058f00f-79bb-47c1-c981-2fe63c61ec9f"
   },
   "outputs": [],
   "source": [
    "loader = DrugbankDDI()\n",
    "context_set = loader.get_context_features()\n",
    "drug_set = loader.get_drug_features()\n",
    "triples = loader.get_labeled_triples()\n",
    "loader.summarize()\n",
    "\n",
    "# 60% train, 40% test and validation\n",
    "train, test_val = triples.train_test_split(train_size=0.6)\n",
    "\n",
    "# split the 40% test/validation in half (i.e. 20% test and 20% validation)\n",
    "val, test = test_val.train_test_split(train_size=0.5)\n",
    "\n",
    "print(\"train:\", len(train))\n",
    "print(\"test:\", len(val))\n",
    "print(\"test:\", len(test))\n",
    "\n",
    "batch_size = 256\n",
    "train_generator = BatchGenerator(batch_size=batch_size,\n",
    "                           context_features=False,\n",
    "                           drug_features=True,\n",
    "                           drug_molecules=False,\n",
    "                           context_feature_set=context_set,\n",
    "                           drug_feature_set=drug_set,\n",
    "                           labeled_triples=train)\n",
    "val_generator = BatchGenerator(batch_size=batch_size,\n",
    "                                 context_features=False,\n",
    "                                 drug_features=True,\n",
    "                                 drug_molecules=False,\n",
    "                                 context_feature_set=context_set,\n",
    "                                 drug_feature_set=drug_set,\n",
    "                                 labeled_triples=val)\n",
    "test_generator = BatchGenerator(batch_size=batch_size,\n",
    "                               context_features=False,\n",
    "                               drug_features=True,\n",
    "                               drug_molecules=False,\n",
    "                               context_feature_set=context_set,\n",
    "                               drug_feature_set=drug_set,\n",
    "                               labeled_triples=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "executionInfo": {
     "elapsed": 878,
     "status": "ok",
     "timestamp": 1713154161237,
     "user": {
      "displayName": "Andrew Vamos",
      "userId": "04562579817850856492"
     },
     "user_tz": 240
    },
    "id": "KUL1_lussamp",
    "outputId": "60ef5ed6-36c7-4eaa-867d-caf23204905a"
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# Data for plotting\n",
    "labels = ['Train', 'Validation', 'Test']\n",
    "sizes = [len(train), len(val), len(test)]\n",
    "df = pd.DataFrame({'Split': labels, 'Size': sizes})\n",
    "\n",
    "fig = px.pie(df, values='Size', names='Split', title='Data Distribution')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3muyDPFPbozY"
   },
   "source": [
    "##   Model\n",
    "Our project utilizes a deep learning architecture designed specifically for predicting drug-drug interactions (DDIs) from drug features. The model's architecture and training processes are detailed below:\n",
    "\n",
    "### Model Architecture:\n",
    "\n",
    "* Layer Configuration: The model is composed of several hidden layers. The number of hidden layers is set dynamically, with experiments run using 8 layers. Each layer utilizes fully connected (dense) neural layers.\n",
    "* Channels and Nodes: The input drug features are processed through drug_channels, which is determined by the data loader. The number of hidden channels per layer is variable, tested with configurations including 128 nodes.\n",
    "* Output: The model outputs a single value per drug pair, representing the probability of interaction, which is then thresholded to classify interactions.\n",
    "* Activation Function: The architecture uses ReLU (Rectified Linear Unit) activation functions throughout the hidden layers to introduce non-linearity, beneficial for learning complex patterns.\n",
    "\n",
    "### Training Objectives:\n",
    "\n",
    "* Loss Function: The model uses the Binary Cross-Entropy Loss (BCELoss), a common choice for binary classification tasks.\n",
    "* Optimizer: Adam optimizer is employed for its efficiency in handling sparse gradients and adaptive learning rate capabilities.\n",
    "* Learning Rate and Epochs: The learning rate is set at 0.0001 with experiments conducted over 100 epochs.\n",
    "\n",
    "### Additional Configuration:\n",
    "\n",
    "* Thresholding: Post-prediction, a threshold of 0.47 is applied to convert the probabilistic outputs into binary interaction predictions.\n",
    "\n",
    "### Code Implementation:\n",
    "The model is encapsulated within a training function that handles the full lifecycle of training and validation. This function initializes the model, sets up the loss criterion and optimizer, and performs epoch-wise training with backpropagation. Post-training, the model is evaluated on a validation set, and metrics such as ROC-AUC, accuracy, recall, precision, and F1 score are calculated to assess performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1713154161238,
     "user": {
      "displayName": "Andrew Vamos",
      "userId": "04562579817850856492"
     },
     "user_tz": 240
    },
    "id": "gBdVZoTvsSFV"
   },
   "outputs": [],
   "source": [
    "def train_fnc(\n",
    "        ddi=DeepDDI,\n",
    "        _drug_channels=256,\n",
    "        _hidden_channels=2048,\n",
    "        _hidden_layers_num=8,\n",
    "        _out_channels=1,\n",
    "        _lr=0.0001,\n",
    "        _epochs=100,\n",
    "        _threshold=0.47,\n",
    "        metrics: Optional[Sequence[str]] = None):\n",
    "\n",
    "    ddi_model = ddi(\n",
    "        drug_channels=_drug_channels,\n",
    "        hidden_channels=_hidden_channels,\n",
    "        hidden_layers_num=_hidden_layers_num,\n",
    "        out_channels=_out_channels\n",
    "    )\n",
    "\n",
    "    optimizer = torch.optim.Adam(ddi_model.parameters(), lr=_lr)\n",
    "    ddi_model.train()\n",
    "    criterion = torch.nn.BCELoss()\n",
    "    losses = []\n",
    "    losses_val = []\n",
    "    train_start_time = time.time()\n",
    "\n",
    "    for epoch in trange(_epochs):\n",
    "        for training_batch in train_generator:\n",
    "            optimizer.zero_grad()\n",
    "            training_prediction = ddi_model(training_batch.drug_features_left, training_batch.drug_features_right)\n",
    "            loss = criterion(training_prediction, training_batch.labels)\n",
    "            losses.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        # print(f\"Epoch {epoch}: epoch_loss={np.mean(losses)}\")\n",
    "\n",
    "    train_time = time.time() - train_start_time\n",
    "\n",
    "    ddi_model.eval()\n",
    "    predictions = []\n",
    "    evaluation_start_time = time.time()\n",
    "\n",
    "    for val_batch in val_generator:\n",
    "        prediction = ddi_model(val_batch.drug_features_left, val_batch.drug_features_right)\n",
    "        loss = criterion(prediction, val_batch.labels)\n",
    "        losses_val.append(loss.item())\n",
    "        if isinstance(prediction, collections.abc.Sequence):\n",
    "            prediction = prediction[0]\n",
    "        prediction = prediction.detach().cpu().numpy()\n",
    "        identifiers = val_batch.identifiers\n",
    "        prediction[prediction >= _threshold] = 1\n",
    "        prediction[prediction < _threshold] = 0\n",
    "        identifiers[\"prediction\"] = prediction\n",
    "        predictions.append(identifiers)\n",
    "\n",
    "    evaluation_time = time.time() - evaluation_start_time\n",
    "    predictions_df = pd.concat(predictions)\n",
    "\n",
    "    if metrics is None:\n",
    "        metric_dict = {\"roc_auc\": roc_auc_score}\n",
    "    else:\n",
    "        metric_dict = {name: metric_resolver.lookup(name) for name in metrics}\n",
    "\n",
    "    return Result(\n",
    "        model=ddi_model,\n",
    "        predictions=predictions_df,\n",
    "        losses=losses,\n",
    "        losses_val=losses_val,\n",
    "        train_time=train_time,\n",
    "        evaluation_time=evaluation_time,\n",
    "        metrics={\n",
    "            name: func(predictions_df[\"label\"], predictions_df[\"prediction\"]) for name, func in metric_dict.items()\n",
    "        },\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PW_lTDZVjP0A"
   },
   "source": [
    "### Training a Simplified Model for Demonstration\n",
    "\n",
    "To demonstrate the training process and model architecture interactively within this notebook, we will train a simplified version of our deep learning model. This streamlined model will utilize fewer resources, making it feasible to train interactively without extensive computational demands.\n",
    "\n",
    "The simplified model will have the following adjustments for efficient demonstration:\n",
    "\n",
    "* Node Configuration: Each layer will consist of only 128 nodes, reducing the complexity of the model.\n",
    "* Epochs: The training will be conducted over only one epoch to provide a quick insight into the model's learning behavior without waiting for extended periods.\n",
    "\n",
    "This approach is intended to give a practical overview of the model's functionality and training dynamics while not replacing the need for full-scale training performed outside this notebook. The code below initializes and trains this model, and briefly evaluates its performance:"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Training Simplified Model with Original Implementation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "metrics=[\"roc_auc\", \"acc\", \"recall\", \"precision\", \"f1\"]\n",
    "drug_channels = loader.drug_channels\n",
    "hidden_nodes = [128]  # -->[128, 256, 512, 1024, 2048] <-- versions we pretrained which will be loaded below\n",
    "hidden_layers = 8\n",
    "epochs = 1 # 100 epochs used in the original paper and our pretrained versions\n",
    "lr=0.0001\n",
    "\n",
    "start = time.time()\n",
    "for node in hidden_nodes:\n",
    "    print(f\"\\nTraining with {hidden_layers} layers and {node} nodes:\")\n",
    "    result = train_fnc(\n",
    "                        ddi=DeepDDI,\n",
    "                        _drug_channels=drug_channels,\n",
    "                        _hidden_channels=node,\n",
    "                        _hidden_layers_num=hidden_layers,\n",
    "                        _out_channels=1,\n",
    "                        _lr=lr,\n",
    "                        _epochs=epochs,\n",
    "                        metrics=metrics)\n",
    "    result.summarize()\n",
    "    # result_dir = f\"./results_org_model/results_{node}_node/\"\n",
    "    result_dir = f\"./results_org/results_{node}_node/\"\n",
    "    result.save(result_dir)\n",
    "\n",
    "time_taken = time.time() - start\n",
    "print(\"time taken:\", time_taken)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Training Simplified Model with Updated Implementation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "metrics=[\"roc_auc\", \"acc\", \"recall\", \"precision\", \"f1\"]\n",
    "drug_channels = loader.drug_channels\n",
    "hidden_nodes = [128]  # -->[128, 256, 512, 1024, 2048] <-- versions we pretrained which will be loaded below\n",
    "hidden_layers = 8\n",
    "epochs = 1 # 100 epochs used in the original paper and our pretrained versions\n",
    "lr=0.0001\n",
    "\n",
    "start = time.time()\n",
    "for node in hidden_nodes:\n",
    "    print(f\"\\nTraining with {hidden_layers} layers and {node} nodes:\")\n",
    "    result = train_fnc(\n",
    "                        ddi=DeepDDI_2,\n",
    "                        _drug_channels=drug_channels,\n",
    "                        _hidden_channels=node,\n",
    "                        _hidden_layers_num=hidden_layers,\n",
    "                        _out_channels=1,\n",
    "                        _lr=lr,\n",
    "                        _epochs=epochs,\n",
    "                        metrics=metrics)\n",
    "    result.summarize()\n",
    "    result_dir = f\"./results_upd_model/results_{node}_node/\"\n",
    "    result.save(result_dir)\n",
    "\n",
    "time_taken = time.time() - start\n",
    "print(\"time taken:\", time_taken)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FDcgcJsJhWuo"
   },
   "source": [
    "### Model Loading and Evaluation\n",
    "\n",
    "Due to the computational intensity and time constraints associated with training our deep learning model for predicting drug-drug interactions, we have pre-trained the model outside of this notebook. This approach allows us to utilize more powerful computational resources and ensure the model is thoroughly trained without the limitations of this interactive environment.\n",
    "\n",
    "Below, we provide the code to load the pre-trained model and the saved results of its performance on a set of test data using the test, validation, and train scheme above. Note that these validation metrics were generated at runtime of the original training of the model since we did not save the data folds as selected by the dataloader for this demonstration on Colab.\n",
    "\n",
    "Strategically subsetting data into train, validation, and test folds is crucial for demonstrating the model’s effectiveness and ensuring that it generalizes well to new, unseen data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 9547,
     "status": "ok",
     "timestamp": 1713154230714,
     "user": {
      "displayName": "Andrew Vamos",
      "userId": "04562579817850856492"
     },
     "user_tz": 240
    },
    "id": "liF9WZFhiCTO",
    "outputId": "0bec379a-4e08-4446-f3eb-57baec472acb"
   },
   "outputs": [],
   "source": [
    "# LOAD PRETRAINED MODELS\n",
    "\n",
    "import gdown\n",
    "\n",
    "node_list = [128, 256, 512, 1024, 2048]\n",
    "file_id = {\"128\":\"1e03P--Qo_aJZL670o0OD4HNGqh6CLEHy\",\n",
    "           \"256\":\"1lCbv0ZzfGgmFY274FllRENSzkTYuA3So\",\n",
    "           \"512\":\"166cPKwsydG_Z-9afpqeBuB6ZUaPDB0zY\",\n",
    "           \"1024\":\"141IpugQZpsRX27VxnOPeAzGK5gUt3YTz\",\n",
    "           \"2048\":\"1TdfpohPb5RjCZ1V8XZiMJQDNLo-qFWV0\"}\n",
    "\n",
    "def load_model( file_id, nodes):\n",
    "  \"\"\"Accepts a file ID and node count to load in a DeepDDI model from gdrive\"\"\"\n",
    "\n",
    "  url = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "  output = f\"model_{nodes}.pkl\"\n",
    "  gdown.download(url, output, quiet=False)\n",
    "  my_model = torch.load(output)\n",
    "  my_model.eval()\n",
    "  return my_model\n",
    "\n",
    "#loading in the torch.save pkl file\n",
    "trained_models = [load_model(file_id[str(node)], node) for node in node_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ZPoLZbo2WJ7"
   },
   "source": [
    "### 128 Node Model Architechture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1713154230714,
     "user": {
      "displayName": "Andrew Vamos",
      "userId": "04562579817850856492"
     },
     "user_tz": 240
    },
    "id": "pXzRp_oJ2M5M",
    "outputId": "71f9fabc-737c-4e96-e827-1ffd57247850"
   },
   "outputs": [],
   "source": [
    "#display model architecture for 128\n",
    "print('/n Architecture for 128 node model: /n')\n",
    "print(trained_models[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "up1IFjlI2fUZ"
   },
   "source": [
    "### 2048 Node Model Architechture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1713154230714,
     "user": {
      "displayName": "Andrew Vamos",
      "userId": "04562579817850856492"
     },
     "user_tz": 240
    },
    "id": "jM-M1dyB2S4B",
    "outputId": "219e4a82-97d5-47ca-9f20-b3d6d3b18fcb"
   },
   "outputs": [],
   "source": [
    "#display model architecture for 2048\n",
    "print('/n Architecture for 2048 node model: /n')\n",
    "print(trained_models[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7tUU46wDRsIp"
   },
   "source": [
    "# Results\n",
    "This section provides a comprehensive overview of the outcomes from both our simplified model trained within this notebook and the pre-trained model loaded from external resources. The results are presented through quantitative metrics and visual representations to clearly demonstrate the model's effectiveness and performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tCZ9QT-mlcEf"
   },
   "source": [
    "## Results from the Pre-trained Model Evaluation\n",
    "\n",
    "After loading the pre-trained model, we evaluated it on a designated test set to assess its generalization capability. This model was trained with the full configuration on extensive computational resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1236
    },
    "executionInfo": {
     "elapsed": 6867,
     "status": "ok",
     "timestamp": 1713154237569,
     "user": {
      "displayName": "Andrew Vamos",
      "userId": "04562579817850856492"
     },
     "user_tz": 240
    },
    "id": "-jxm-dn2t_IX",
    "outputId": "226b6aea-1e60-4bfd-ffaf-e70176e62795"
   },
   "outputs": [],
   "source": [
    "#results stored on the google drive of Team 8\n",
    "results_id = {\"128\":\"1F2lr5QE3RuQt3j86dhafqDYatxHSLMVl\",\n",
    "           \"256\":\"17r74vGCn9nLjsLW_KR4_e6DG0_-87rqv\",\n",
    "           \"512\":\"1GOoy54Iws_qV_1gB7PAm1wT1mqG4bptN\",\n",
    "           \"1024\":\"1Y6gkLMXgcZ4Z4ETH2CCbnHKuIbW_QVhC\",\n",
    "           \"2048\":\"1-pBd5QAsQ_xP6Jyx-yEulZyO6V9k_NHt\"}\n",
    "\n",
    "def load_results(file_id, nodes):\n",
    "    \"\"\"Accepts a result file ID and node count to load in a DeepDDI model from gdrive\"\"\"\n",
    "    url = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "    output = f\"model_{nodes}.json\"\n",
    "    gdown.download(url, output, quiet=True)\n",
    "    with open(output, 'r') as model_results:\n",
    "        results_json = json.load(model_results)\n",
    "    return results_json\n",
    "\n",
    "\n",
    "roc_auc = []\n",
    "acc = []\n",
    "recall = []\n",
    "precision = []\n",
    "f1 = []\n",
    "training_time = []\n",
    "evaluation_time = []\n",
    "nodes = []\n",
    "all_losses = []\n",
    "losses_tr = []\n",
    "\n",
    "%matplotlib inline\n",
    "print(\"The following metrics were saved from the training of our preloaded \\n models via the training code demonstrated above. \\n\")\n",
    "for node, file_id in results_id.items():\n",
    "    results_json = load_results(file_id, node)\n",
    "\n",
    "    nodes.append(int(node))\n",
    "\n",
    "    print(f\"Runtime results for model_{node}:\")\n",
    "    print(f\"ROC AUC: {results_json['evaluation']['roc_auc']}\")\n",
    "    print(f\"Accuracy: {results_json['evaluation']['acc']}\")\n",
    "    print(f\"Recall: {results_json['evaluation']['recall']}\")\n",
    "    print(f\"Precision: {results_json['evaluation']['precision']}\")\n",
    "    print(f\"F1 Score: {results_json['evaluation']['f1']}\")\n",
    "    print(f\"Training Time (s): {float(results_json['training_time'])}\")\n",
    "    #print(f\"Evaluation Time (s): {results_json['evaluation_time']}\")\n",
    "    print(f\"losses: {results_json['losses'][:3]} ... {results_json['losses'][-3:]}\")\n",
    "\n",
    "    roc_auc.append(results_json['evaluation']['roc_auc'])\n",
    "    acc.append(results_json['evaluation']['acc'])\n",
    "    recall.append(results_json['evaluation']['recall'])\n",
    "    precision.append(results_json['evaluation']['precision'])\n",
    "    f1.append(results_json['evaluation']['f1'])\n",
    "    training_time.append(float(results_json['training_time'])/60/60)\n",
    "    evaluation_time.append(results_json['evaluation_time'])\n",
    "    losses_tr.append(results_json['losses'])\n",
    "    plt.plot(results_json['losses'], label=f'model_{node}')\n",
    "\n",
    "plt.title('Losses')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print() #do not remove, prevents duplicate plot bug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "executionInfo": {
     "elapsed": 316,
     "status": "ok",
     "timestamp": 1713154237882,
     "user": {
      "displayName": "Andrew Vamos",
      "userId": "04562579817850856492"
     },
     "user_tz": 240
    },
    "id": "V0HcBaiMxy39",
    "outputId": "ccb16209-f212-473f-d547-c7c264de7b86"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "epoch_averages = []\n",
    "for loss_list in losses_tr:\n",
    "    avg_list = []\n",
    "    epoch_size = len(loss_list) // 100\n",
    "    for i in range(0, len(loss_list), epoch_size):\n",
    "        avg = sum(loss_list[i:i+epoch_size]) / epoch_size\n",
    "        avg_list.append(avg)\n",
    "    epoch_averages.append(avg_list)\n",
    "results_nodes = [\"128\", \"256\", \"512\", \"1024\", \"2048\"]\n",
    "df_losses = pd.DataFrame([res for res in epoch_averages])\n",
    "df_losses.index = [f'{results_nodes[0]} Nodes', f'{results_nodes[1]} Nodes',\n",
    "            f'{results_nodes[2]} Nodes', f'{results_nodes[3]} Nodes',\n",
    "            f'{results_nodes[4]} Nodes']\n",
    "plt.plot(epoch_averages[0],linestyle='-', color='red', label='128 Nodes')\n",
    "plt.plot(epoch_averages[1],linestyle='-', color='blue', label='256 Nodes')\n",
    "plt.plot(epoch_averages[2],linestyle='-', color='green', label='512 Nodes')\n",
    "plt.plot(epoch_averages[3],linestyle='-', color='black', label='1024 Nodes')\n",
    "plt.plot(epoch_averages[4],linestyle='-', color='orange', label='2048 Nodes')\n",
    "\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss Values Per Epoch\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()\n",
    "print() #do not remove, prevents duplicate plot bug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 636
    },
    "executionInfo": {
     "elapsed": 637,
     "status": "ok",
     "timestamp": 1713154238516,
     "user": {
      "displayName": "Andrew Vamos",
      "userId": "04562579817850856492"
     },
     "user_tz": 240
    },
    "id": "C-8NhwCcOUAi",
    "outputId": "35ba4caf-5f3a-4505-e9d2-1d2e3dfe780b"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "df_val = pd.DataFrame({\n",
    "    'roc_auc': roc_auc,\n",
    "    'acc': acc,\n",
    "    'recall': recall,\n",
    "    'precision': precision,\n",
    "    'f1': f1\n",
    "})\n",
    "results_nodes = [\"128\", \"256\", \"512\", \"1024\", \"2048\"]\n",
    "df_val.index = [f'{results_nodes[0]} Nodes', f'{results_nodes[1]} Nodes',\n",
    "            f'{results_nodes[2]} Nodes', f'{results_nodes[3]} Nodes',\n",
    "            f'{results_nodes[4]} Nodes']\n",
    "df_val.plot(kind='bar', figsize=(10, 6))\n",
    "plt.title(\"Model Metrics Comparison on Validation Set\")\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"Metric Value\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "print() #do not remove, prevents duplicate plot bug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1713154238516,
     "user": {
      "displayName": "Andrew Vamos",
      "userId": "04562579817850856492"
     },
     "user_tz": 240
    },
    "id": "tvO8G-LB6wqe"
   },
   "outputs": [],
   "source": [
    "def test_fnc(_ddi_model,\n",
    "         _threshold=0.47,\n",
    "         metrics=metrics):\n",
    "\n",
    "    _ddi_model.eval()\n",
    "    predictions = []\n",
    "\n",
    "    for test_batch in test_generator:\n",
    "        prediction = _ddi_model(test_batch.drug_features_left, test_batch.drug_features_right)\n",
    "        if isinstance(prediction, collections.abc.Sequence):\n",
    "            prediction = prediction[0]\n",
    "        prediction = prediction.detach().cpu().numpy()\n",
    "        identifiers = test_batch.identifiers\n",
    "        prediction[prediction >= _threshold] = 1\n",
    "        prediction[prediction < _threshold] = 0\n",
    "        identifiers[\"prediction\"] = prediction\n",
    "        predictions.append(identifiers)\n",
    "\n",
    "    predictions_df = pd.concat(predictions)\n",
    "\n",
    "    if metrics is None:\n",
    "        metric_dict = {\"roc_auc\": roc_auc_score}\n",
    "    else:\n",
    "        metric_dict = {name: metric_resolver.lookup(name) for name in metrics}\n",
    "\n",
    "    return {name: func(predictions_df[\"label\"], predictions_df[\"prediction\"]) \\\n",
    "            for name, func in metric_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 92503,
     "status": "ok",
     "timestamp": 1713154331016,
     "user": {
      "displayName": "Andrew Vamos",
      "userId": "04562579817850856492"
     },
     "user_tz": 240
    },
    "id": "EZs5wQ8MOuzj",
    "outputId": "f8d84354-8dc0-433f-e1db-b9020ac2c720"
   },
   "outputs": [],
   "source": [
    "test_results = []\n",
    "results_nodes = [\"128\", \"256\", \"512\", \"1024\", \"2048\"]\n",
    "for idx, model in enumerate(trained_models):\n",
    "    print(f\"\\nTesting model with {results_nodes[idx]} nodes in each layer ...\")\n",
    "    res = test_fnc(model)\n",
    "    # for k,v in res.items():\n",
    "        # print(k, \":\", round(v, 3))\n",
    "    test_results.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 636
    },
    "executionInfo": {
     "elapsed": 428,
     "status": "ok",
     "timestamp": 1713154331433,
     "user": {
      "displayName": "Andrew Vamos",
      "userId": "04562579817850856492"
     },
     "user_tz": 240
    },
    "id": "XB4UdWPBO1YL",
    "outputId": "17b87d03-f45e-4ae4-e9fd-7a9b13216a0e"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "df_test = pd.DataFrame([res for res in test_results])\n",
    "df_test.index = [f'{results_nodes[0]} Nodes', f'{results_nodes[1]} Nodes',\n",
    "            f'{results_nodes[2]} Nodes', f'{results_nodes[3]} Nodes',\n",
    "            f'{results_nodes[4]} Nodes']\n",
    "df_test.plot(kind='bar', figsize=(10, 6))\n",
    "plt.title(\"Model Metrics Comparison on Test Set\")\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"Metric Value\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "print() #do not remove, prevents duplicate plot bug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 581
    },
    "executionInfo": {
     "elapsed": 386,
     "status": "ok",
     "timestamp": 1713154331818,
     "user": {
      "displayName": "Andrew Vamos",
      "userId": "04562579817850856492"
     },
     "user_tz": 240
    },
    "id": "UI4_3gJrO35f",
    "outputId": "b7037572-eb6b-4fff-d2f0-700408bb22fa"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df_val.index, df_val['roc_auc'], marker='o', label='Validation Set')\n",
    "plt.plot(df_test.index, df_test['roc_auc'], marker='x', label='Test Set')\n",
    "plt.title(\"roc_auc Comparison\")\n",
    "plt.xlabel(\"Nodes\")\n",
    "plt.ylabel(\"roc_auc Value\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "print() #do not remove, prevents duplicate plot bug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qH75TNU71eRH"
   },
   "source": [
    "# Discussion\n",
    "\n",
    "This section reflects on the replication attempt of the original study's findings using the DeepDDI model, providing insights into the reproducibility of the paper, challenges encountered, and potential improvements for future research efforts.\n",
    "## Assessment of Reproducibility\n",
    "\n",
    "Based on our experiments, the original paper's results are partially reproducible. The model's performance with a high number of nodes (2048 and 1024) approached the claimed outcomes, suggesting that under optimal conditions and with substantial computational resources, the model can indeed perform at a high level. However, as the number of nodes decreased, there was a noticeable drop in all metrics, particularly with the smallest model (128 nodes), which significantly underperformed.\n",
    "Challenges in Reproduction\n",
    "\n",
    "### What Was Easy:\n",
    "\n",
    "* Model Architecture Implementation: The clear description of the model architecture in the original paper made it straightforward to implement and test various configurations.\n",
    "* Data Processing and Loading: Utilizing the DrugBank<sup>[4]</sup> dataset and the provided data handling tools facilitated an efficient setup for training and evaluation.\n",
    "\n",
    "### What Was Difficult:\n",
    "\n",
    "* Resource Constraints: Training larger models with thousands of nodes required substantial computational resources, which posed a challenge in environments with limited capacity like standard Colab notebooks.\n",
    "* Reaching Reported Metrics: While the highest configurations nearly reached the reported metrics, achieving consistent results across different settings proved challenging, especially with lower resource models.\n",
    "\n",
    "### Suggestions for Improving Reproducibility\n",
    "\n",
    "* Detailed Configuration: Future reproductions would benefit from more detailed descriptions of the training conditions, including specifics on the computational environment and hyperparameter tuning processes.\n",
    "\n",
    "## Future Plan\n",
    "\n",
    "### Ablation Study on Feature Selection\n",
    "\n",
    "In the next phase of our project, we aim to delve deeper into the feature selection process employed in our models. Currently, our approach involves using the first 256 features from the chemical structures, a method that simplifies the preprocessing but may not optimally capture the most informative aspects of the data, given that the total number of features is 2159.\n",
    "\n",
    "To enhance the effectiveness of our feature selection and potentially improve model performance, we plan to conduct an ablation study comparing our current method with a Principal Component Analysis (PCA) approach. PCA is a powerful technique for dimensionality reduction that transforms a large set of variables into a smaller one that still contains most of the information in the large set. By applying PCA, we hope to:\n",
    "\n",
    "* Reduce the dimensionality of the chemical structure features from 2159 to a more manageable number, focusing on the components that capture the most variance and, presumably, the most information.\n",
    "* Identify the most informative features rather than arbitrarily selecting the first 256. This could potentially uncover hidden patterns in the chemical data that are more predictive of drug interactions.\n",
    "\n",
    "This study will involve:\n",
    "\n",
    "* Implementing PCA on the entire set of 2159 chemical structure features to reduce them to a principal component space that retains most of the variance.\n",
    "* Integrating these PCA-transformed features into the ChemicalX framework<sup>[2]</sup> and training the model to assess any changes in performance metrics compared to the baseline model using the first 256 features.\n",
    "* Evaluating the models on several metrics to compare their effectiveness in predicting drug-drug interactions. We will specifically look at accuracy, precision, recall, F1 score, and AUC to determine if PCA provides a significant benefit.\n",
    "\n",
    "The outcome of this ablation study will not only inform our feature selection strategy but also contribute to broader research by demonstrating the impact of different feature reduction techniques on the performance of models predicting complex biological interactions. This approach aligns with our commitment to enhancing the reproducibility and reliability of computational tools in drug discovery.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SHMI2chl9omn"
   },
   "source": [
    "# References\n",
    "\n",
    "1. Ryu JY, Kim HU, Lee SY (2018) Deep learning improves prediction of drug–drug and drug–food interactions. Proceedings of the National Academy of Sciences 115(18). doi:10.1073/pnas.1803294115.\n",
    "1. AstraZeneca, ChemicalX: A PyTorch and TorchDrug based deep learning library for drug pair scoring. GitHub repository, 2022. [Online]. Available: https://github.com/AstraZeneca/chemicalx/\n",
    "1. Fonseca Santiesteban, A., ChemicalX fork for Python 3.10 compatibility. GitHub repository, 2024. [Online]. Available: https://github.com/lucag2/chemicalx#egg=chemicalx\n",
    "1. Wishart DS, et al. (2017) DrugBank 5.0: A major update to the DrugBank database for 2018. Nucleic Acids Res 46:D1074–D1082."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1oAKqszNlwEZwPa_BjHPqfcoWlikYBpi5",
     "timestamp": 1709153069464
    }
   ]
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
